{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#from keras import backend as K\n",
    "#from keras.models import Model, model_from_json\n",
    "#from keras.layers import Input, Dense, Flatten\n",
    "\n",
    "#from prednet import PredNet\n",
    "#from data_utils import SequenceGenerator\n",
    "from kitti_settings import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 40\n",
    "batch_size = 15\n",
    "nt = 15\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deseja mudar os nomes dos arquivos ?n\n",
      "nome dos arquivos:./model_data_keras2/prednet_kitti_weights_nt15_t5_a3.hdf5\n",
      "./model_data_keras2/prednet_kitti_model_nt15_t5_a3.json\n"
     ]
    }
   ],
   "source": [
    "resp = raw_input('deseja mudar os nomes dos arquivos ?')\n",
    "if str(resp) == 'yes' or str(resp) == 'sim' or str(resp) == 's' or str(resp) == 'y':\n",
    "    peso_hdf = raw_input('weights_file:') \n",
    "    peso_json = raw_input('json weight file:')\n",
    "    weights_file = os.path.join(WEIGHTS_DIR, str(peso_hdf))\n",
    "    json_file = os.path.join(WEIGHTS_DIR,str(peso_json))\n",
    "else:\n",
    "    weights_file = os.path.join(WEIGHTS_DIR, 'prednet_kitti_weights_nt15_t5_a3.hdf5')\n",
    "    json_file = os.path.join(WEIGHTS_DIR, 'prednet_kitti_model_nt15_t5_a3.json')\n",
    "    test_file = os.path.join(DATA_DIR, 'X_val.hkl')\n",
    "    test_sources = os.path.join(DATA_DIR, 'sources_val.hkl')\n",
    "print 'nome dos arquivos:'+ weights_file+'\\n'+json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "f = open(json_file, 'r')\n",
    "json_string = f.read()\n",
    "f.close()\n",
    "train_model = model_from_json(json_string, custom_objects = {'PredNet': PredNet})\n",
    "train_model.load_weights(weights_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create testing model (to output predictions)\n",
    "layer_config = train_model.layers[1].get_config()\n",
    "layer_config['output_mode'] = 'prediction'\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config else layer_config['dim_ordering']\n",
    "test_prednet = PredNet(weights=train_model.layers[1].get_weights(), **layer_config)\n",
    "input_shape = list(train_model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = nt\n",
    "inputs = Input(shape=tuple(input_shape))\n",
    "predictions = test_prednet(inputs)\n",
    "test_model = Model(inputs=inputs, outputs=predictions)\n",
    "test_generator = SequenceGenerator(test_file, test_sources, nt, sequence_start_mode='unique', data_format=data_format)\n",
    "X_test = test_generator.create_all()\n",
    "X_hat = test_model.predict(X_test, batch_size)\n",
    "if data_format == 'channels_first':\n",
    "    X_test = np.transpose(X_test, (0, 1, 3, 4, 2))\n",
    "    X_hat = np.transpose(X_hat, (0, 1, 3, 4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_save_dir = '/home/daniel/AnacondaProjects/prednet-master_2/kitti_results/hdf-result'\n",
    "import hickle as hkl\n",
    "if not os.path.exists(plot_save_dir): os.mkdir(plot_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resp = raw_input('deseja mudar os nomes dos arquivos antes de salvar?')\n",
    "if str(resp) == 'yes' or str(resp) == 'sim' or str(resp) == 's' or str(resp) == 'y':\n",
    "    nome_xhat_saver = raw_input('digite nome X_hat')\n",
    "    x_hat_saver = os.path.join (plot_save_dir,str(nome_xhat_saver))\n",
    "else:\n",
    "    x_hat_saver = os.path.join (plot_save_dir,'X_hat_test_model_nt15_t5_a3.hkl')\n",
    "print 'o arquivo será salvo com o nome:', nome_xhat_saver\n",
    "hkl.dump(X_hat,x_hat_saver)\n",
    "print 'Pronto!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resp = raw_input('deseja mudar os nomes dos arquivos antes de salvar?')\n",
    "if str(resp) == 'yes' or str(resp) == 'sim' or str(resp) == 's' or str(resp) == 'y':\n",
    "    nome_xtest_saver = raw_input('digite nome X_test')\n",
    "    x_test_saver = os.path.join (plot_save_dir,str(nome_xtest_saver))\n",
    "else:\n",
    "    x_test_saver = os.path.join (plot_save_dir,'X_test_model_nt15_t5_a3.hkl')\n",
    "print 'o arquivo será salvo com o nome:', nome_xtest_saver\n",
    "hkl.dump(X_test,x_test_saver)\n",
    "print 'Pronto!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
